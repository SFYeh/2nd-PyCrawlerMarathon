# 2nd-PyCrawlerMarathon
## 【FINAL PROJECT】

## 【LEARNING NOTE】
### 1. INTRODUCTION
#### Data Source & File IO || DAY1 
|Data Source     |       |
| ------------- |:-------------:     
| file       |csv, json, xml       |
| API          | [what is API](https://www.youtube.com/watch?v=zvKadd9Cflc)     |
| Crawler     |  website    | 

| File I/O |       |
| ------------- |:-------------:      
| urllib      |Download data by url    |
| os         | Manipulate file directory|
| (file handling)  | open--> 'r', 'w', 'a' -->close |
| cardet     |  Identify encoding type|



#### Data IO：CSV || DAY2
| library       |command            |缺點|
| ------------- |:-------------:     | -----:|
| pandas        |pd.read_csv()       | |
| csv           |csv.reader()       |需要另外將資料儲存成變數並整合之後才能使用 |

see more ：[Reading and Writing CSV Files in Python](https://realpython.com/python-csv/)
#### Data IO：XML || DAY3

### 2. STATIC WEBPAGE

### 3. DYNAMIC WEBPAGE

### 4. DIGGING DEEPER
